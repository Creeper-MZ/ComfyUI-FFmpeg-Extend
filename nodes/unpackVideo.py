"""
UnpackVideo èŠ‚ç‚¹ - å°†VideoDataè§£ä¸ºComfyUIå…¼å®¹çš„IMAGEå¼ é‡
"""

import os
import tempfile
from PIL import Image, ImageOps
import torch
import numpy as np
import comfy
from ..video_types import VideoData
from ..func import extract_frames_from_bytes


class UnpackVideo:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video": ("VIDEO",),
            },
            "optional": {
                "scale_factor": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 4.0, "step": 0.1}),
            },
        }

    RETURN_TYPES = ("IMAGE", "INT", "FLOAT", "INT", "INT")
    RETURN_NAMES = ("images", "frame_count", "fps", "width", "height")
    FUNCTION = "unpack_video"
    OUTPUT_NODE = False
    CATEGORY = "ğŸ”¥FFmpeg/Video"

    def unpack_video(self, video, scale_factor=1.0):
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯VideoDataå¯¹è±¡
            if not isinstance(video, VideoData):
                raise ValueError("Input must be a VideoData object")

            # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾æå–çš„å¸§
            with tempfile.TemporaryDirectory() as tmp_dir:
                # ä»è§†é¢‘å­—èŠ‚ä¸­æå–å¸§
                total_frames, fps, width, height = extract_frames_from_bytes(
                    video.to_bytes(),
                    tmp_dir,
                    fps_scale=scale_factor if scale_factor != 1.0 else None
                )

                # åŠ è½½æå–çš„å¸§ä¸ºIMAGEå¼ é‡
                images = []
                frame_files = sorted([f for f in os.listdir(tmp_dir) if f.startswith('frame_')])

                for frame_file in frame_files:
                    frame_path = os.path.join(tmp_dir, frame_file)
                    try:
                        with Image.open(frame_path) as img:
                            img = ImageOps.exif_transpose(img).convert("RGB")
                            # è½¬æ¢ä¸ºå¼ é‡ (1, height, width, channels)
                            image_tensor = torch.from_numpy(
                                np.array(img).astype(np.float32) / 255.0
                            ).unsqueeze(0)
                            images.append(image_tensor)
                    except Exception as e:
                        print(f"Error processing frame {frame_file}: {e}")
                        continue

                if not images:
                    raise ValueError("No frames extracted from video")

                # åˆå¹¶æ‰€æœ‰å¸§
                if len(images) == 1:
                    result_images = images[0]
                else:
                    # æ£€æŸ¥å¹¶è°ƒæ•´ä¸åŒå°ºå¯¸çš„å¸§
                    base_image = images[0]
                    for i in range(1, len(images)):
                        if base_image.shape[1:] != images[i].shape[1:]:
                            # è°ƒæ•´å¤§å°ä»¥åŒ¹é…
                            images[i] = comfy.utils.common_upscale(
                                images[i].movedim(-1, 1),
                                base_image.shape[3],
                                base_image.shape[2],
                                "bilinear",
                                "center"
                            ).movedim(1, -1)

                    result_images = torch.cat(images, dim=0)

                return (result_images, total_frames, fps, width, height)
        except Exception as e:
            raise ValueError(f"Failed to unpack video: {e}")
